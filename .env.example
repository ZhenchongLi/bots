# ==============================================
# Multi-Platform AI API Proxy Configuration
# ==============================================

# Server Configuration
# ----------------------------------
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=info

# Database Configuration
# ----------------------------------
# SQLite database for request/response logging
DATABASE_URL=sqlite+aiosqlite:///./data/proxy.db

# Logging Configuration
# ----------------------------------
LOG_FILE_PATH=./logs/proxy.log
LOG_RETENTION_DAYS=30

# Single Model Configuration
# ----------------------------------
# Configure the AI model/platform you want to use
# All requests will be routed to this single configured model

# Platform type (openai, anthropic, google, azure_openai, custom)
TYPE=openai

# API credentials
API_KEY=your_api_key_here
BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1

# Model settings
ENABLED=true
ACTUAL_NAME=gpt-3.5-turbo
MAX_TOKENS=4096
SUPPORTS_STREAMING=true
SUPPORTS_FUNCTION_CALLING=true

# Optional settings
DISPLAY_NAME=
DESCRIPTION=
TIMEOUT=300
COST_PER_1K_INPUT_TOKENS=
COST_PER_1K_OUTPUT_TOKENS=

# ==============================================
# Quick Start Examples
# ==============================================

# Example 1: OpenAI GPT-4
# TYPE=openai
# API_KEY=sk-your-openai-api-key
# BASE_URL=https://api.openai.com/v1
# ACTUAL_NAME=gpt-4

# Example 2: Claude 3 Sonnet
# TYPE=anthropic
# API_KEY=sk-ant-your-anthropic-key
# BASE_URL=https://api.anthropic.com/v1
# ACTUAL_NAME=claude-3-sonnet-20240229

# Example 3: Google Gemini Pro
# TYPE=google
# API_KEY=your-google-api-key
# BASE_URL=https://generativelanguage.googleapis.com/v1
# ACTUAL_NAME=gemini-pro

# Example 4: Azure OpenAI
# TYPE=azure_openai
# API_KEY=your-azure-api-key
# BASE_URL=https://your-resource.openai.azure.com/openai/deployments/your-deployment
# ACTUAL_NAME=gpt-4

# Example 5: Local Models (Ollama)
# TYPE=custom
# API_KEY=not-needed
# BASE_URL=http://localhost:11434/v1
# ACTUAL_NAME=llama2